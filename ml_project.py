# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cjPW7sBnVN9XmuBRbSH-7FqG5tUDTNqg
"""

'''-->PREPROCESING'''
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler


# 1. Load the dataset
df = pd.read_csv("/content/drive/MyDrive/BMW Sales Data Modified.csv")
print("Dataset Loaded Successfully!\n")
print("First 5 rows:")
print(df.head())

# 2. Check basic info
print("\nDataset Info:")
print(df.info())

# 3. Check for missing values
print("\nMissing Values:")
print(df.isnull().sum())

# 4. Handle categorical data using Label Encoding
label_encoders = {}
for column in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

# 5. Separate features (X) and target (y)
# Replace 'target_column' with your actual target column name
target_column = "Sales_Classification" # <-- change this if needed
if target_column in df.columns:
    X = df.drop(target_column, axis=1)
    y = df[target_column]
else:
    print("please update the target_column with the correct column name")

# 6. Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 7. Scale numerical features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("\nPreprocessing Done!")
print("Training Set Shape:", X_train.shape)
print("Testing Set Shape:", X_test.shape)


'''-->MAINFILE'''
import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

#KNN
print("\nKNN")
knn = KNeighborsClassifier(n_neighbors=3, weights='distance')
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("KNN Accuracy:", round(accuracy_score(y_test, y_pred) * 100, 2), "%")

#DECISION TREE
print("\nDecision Tree")
dt = DecisionTreeClassifier(max_depth=10, min_samples_split=4, random_state=42)
dt.fit(X_train, y_train)
y_pred = dt.predict(X_test)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Decision Tree Accuracy:", round(accuracy_score(y_test, y_pred) * 100, 2), "%")

#RANDOM FOREST
print("\nRandom Forest")
rf = RandomForestClassifier(n_estimators=200, max_depth=12, random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Random Forest Accuracy:", round(accuracy_score(y_test, y_pred) * 100, 2), "%")

#SVM
print("\nSVM")
svm = SVC(kernel='rbf', C=10, gamma=0.1, random_state=42)
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("SVM Accuracy:", round(accuracy_score(y_test, y_pred) * 100, 2), "%")

#NAIVE BAYES
print("\nNaive Bayes")
nb = GaussianNB(var_smoothing=1e-9)
nb.fit(X_train, y_train)
y_pred = nb.predict(X_test)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Naive Bayes Accuracy:", round(accuracy_score(y_test, y_pred) * 100, 2), "%")


'''-->ML MODELS GRAPH'''
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix

# Store models
models = {
    "KNN": KNeighborsClassifier(n_neighbors=3, weights='distance'),
    "Decision Tree": DecisionTreeClassifier(max_depth=12, min_samples_split=8, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=200, max_depth=12, random_state=42),
    "SVM": SVC(kernel='rbf', C=10, gamma=0.1, random_state=42),
    "Naive Bayes": GaussianNB(var_smoothing=1e-9)
}

# Confusion Matrix Heatmaps
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)

    plt.figure(figsize=(5, 4))
    plt.imshow(cm, cmap="Oranges")
    plt.title(f"{name} Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.colorbar()

    # Show values inside cells
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, cm[i, j], ha="center", va="center", color="black")

    plt.show()


'''-->VISUALIZATIONS'''
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

# Load the dataset
file_path = "/content/drive/MyDrive/BMW Sales Data Modified.csv"
df = pd.read_csv(file_path)

# Drop useless columns (example: ID or Date if they exist)
columns_to_drop = ["id", "date"]
for col in columns_to_drop:
    if col in df.columns:
        df = df.drop(col, axis=1)

# Handle categorical data using Label Encoding
label_encoders = {}
for column in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

# Identify numerical columns
numerical_cols = df.select_dtypes(include=np.number).columns.tolist()

#Visualizations

# 1. Heatmap - Correlation between features
plt.figure(figsize=(14, 8))
sns.heatmap(df.corr(numeric_only=True), annot=False, cmap="coolwarm", linewidths=0.5)
plt.title("Feature Correlation Heatmap - BMW Sales Data")
plt.show()

# 2. Histograms - Distribution of numerical attributes
for col in numerical_cols:
    plt.figure(figsize=(8, 2))
    sns.histplot(df[col], kde=True, bins=20, color='skyblue')
    plt.title(f"Histogram of {col}")
    plt.show()

# 3. Scatterplots - Example relationships (using some relevant numerical columns from the BMW data)
# Update selected_numerical_for_scatter to include only columns present in df
import matplotlib.pyplot as plt

# Pick any numerical columns from your dataset
x_col = "Mileage_KM"       # Example X-axis
y_col = "Price_USD"        # Example Y-axis
color_col = "Model"        # This must be 0/1 column

plt.figure(figsize=(10, 6))

# Plot Model = 0 (blue points)
plt.scatter(
    df[df[color_col] == 0][x_col],
    df[df[color_col] == 0][y_col],
    color="blue", alpha=0.5, s=15, label=f"{color_col} = 0"
)

# Plot Model = 1 (red points)
plt.scatter(
    df[df[color_col] == 1][x_col],
    df[df[color_col] == 1][y_col],
    color="red", alpha=0.5, s=15, label=f"{color_col} = 1"
)

plt.title(f"Scatter Plot: {x_col} vs {y_col}", fontsize=14)
plt.xlabel(x_col, fontsize=12)
plt.ylabel(y_col, fontsize=12)
plt.legend(title=color_col)

plt.tight_layout()
plt.show()


'''-->PREDICTION'''
import pandas as pd
from sklearn.preprocessing import LabelEncoder

print("\n========== Predicting for a New Sample ==========\n")

# Example new sample (must match dataset features!)
new_sample = pd.DataFrame([{
    'Model': 'X5',
    'Year': 2024,
    'Region': 'Europe',
    'Color': 'Black',
    'Fuel_Type': 'Petrol',
    'Transmission': 'Automatic',
    'Engine_Size_L': 4.4,
    'Mileage_KM': 10000,
    'Price_USD': 85000,
    'Sales_Volume': 7000
}])

# Apply label encoding (for categorical columns)
for column, le in label_encoders.items():
    if column in new_sample.columns:
        new_sample[column] = le.transform(new_sample[column])

# Apply scaling (numerical features)
new_sample_scaled = scaler.transform(new_sample)

print("\nProcessed & Scaled New Sample (ready for prediction):")
print(new_sample_scaled)

# Dictionary to store predictions
predictions = {}

for name, model in models.items():
    pred = model.predict(new_sample_scaled)[0]
    # Assuming "1 = Yes (High Sales)" and "0 = No (Low Sales)"
    predictions[name] = "Yes" if pred == 1 else "No"

# Print results
print("\nPredictions for New Sample:")
for model_name, result in predictions.items():
    print(f"{model_name} Prediction â†’ {result}")